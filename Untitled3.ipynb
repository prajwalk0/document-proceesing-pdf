{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93d56a0-9f25-4750-a5ee-cf6611c8f3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pymupdf\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from happytransformer import HappyTextToText, TTSettings\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6705c70-25fd-42c9-9494-c1de6050bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the grammercheck class\n",
    "class GrammarChecker:\n",
    "     def __init__(self):\n",
    "         self.grammar_check = HappyTextToText(\"T5\",\"vennify/t5-base-grammar-correction\")\n",
    "         self.beam_settings = TTSettings(num_beams=5, min_length=1, max_length=20)\n",
    "\n",
    "     def correct_grammar(self, text):\n",
    "         # Generate corrected text from the grammar model\n",
    "         matches = self.grammar_check.generate_text(\"gec: \" + text, args=self.beam_settings)\n",
    "\n",
    "         # Extract original and corrected text\n",
    "         original_text = text\n",
    "         corrected_text = matches.text if matches and matches.text else text\n",
    "\n",
    "         return original_text, corrected_text\n",
    "\n",
    "     def highlight_errors(self, original_text, corrected_text):\n",
    "         original_tokens = original_text.split()\n",
    "         corrected_tokens = corrected_text.split()\n",
    "         highlighted_text = original_text\n",
    "\n",
    "         # Find the incorrect words and highlight them\n",
    "         for i in range(max(len(original_tokens),len(corrected_tokens))):\n",
    "             if i < len(original_tokens) and (i >= len(corrected_tokens) or original_tokens[i] != corrected_tokens[i]):\n",
    "                 highlighted_text = highlighted_text.replace(original_tokens[i], f\"**{original_tokens[i]}**\", 1)\n",
    "\n",
    "         return highlighted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccf8b1b9-a2c7-48ed-9cd5-fc0eb003706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 10:55:46 - INFO - happytransformer.happy_transformer -   Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "#Initialize grammer checker\n",
    "grammer_checker = GrammarChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66645ad2-2ce1-448c-814f-075f5e4c4a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_formatter(text):\n",
    "    cleaned_text = text.replace(\"\\n\", \"\").strip()\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0261eeb9-3bad-4b9e-ae28-f054113556aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_and_read_pdf(pdf_path):\n",
    "    doc =pymupdf.open(pdf_path)\n",
    "    pages_and_text = []\n",
    "    for page_number,page in tqdm(enumerate(doc),total=doc.page_count):\n",
    "        text = page.get_text() #get plain text encoded as UTF-8\n",
    "        text = text_formatter(text)\n",
    "        pages_and_text.append({\"page_number\":page_number ,\n",
    "                               \"page_char_count\":len(text),\n",
    "                               \"page_word_count\":len(text.split(\" \")),\n",
    "                               \"page_sentence_count_raw\":len(text.split(\".\")),\n",
    "                               \"page_token_count\":len(text)/4,\n",
    "                               \"text\":text})\n",
    "        \n",
    "    return pages_and_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85d2996f-0b4f-471c-b406-0a512cb9524e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb971ebfee914e33a44ea02c710fc6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf_path = \"US_Declaration.pdf\"\n",
    "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02d39043-10d8-43a3-b11a-b584f1a35068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 4,\n",
       "  'page_char_count': 623,\n",
       "  'page_word_count': 134,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 155.75,\n",
       "  'text': 'George Clymer   James Smith   George Taylor   James Wilson   George Ross Delaware:   Caesar Rodney   George Read   Thomas McKean [Column 5] New York:   William Floyd   Philip Livingston   Francis Lewis   Lewis Morris New Jersey:   Richard Stockton   John Witherspoon   Francis Hopkinson   John Hart   Abraham Clark [Column 6] New Hampshire:   Josiah Bartlett   William Whipple Massachusetts:   Samuel Adams   John Adams   Robert Treat Paine   Elbridge Gerry Rhode Island:   Stephen Hopkins   William Ellery Connecticut:   Roger Sherman   Samuel Huntington   William Williams   Oliver Wolcott New Hampshire: Matthew Thornton'},\n",
       " {'page_number': 3,\n",
       "  'page_char_count': 1131,\n",
       "  'page_word_count': 212,\n",
       "  'page_sentence_count_raw': 6,\n",
       "  'page_token_count': 282.75,\n",
       "  'text': 'between them and the State of Great Britain, is and ought to be totally dissolved; and that as Freeand Independent States, they have full Power to levy War, conclude Peace, contract Alliances,establish Commerce, and to do all other Acts and Things which Independent States may of rightdo. And for the support of this Declaration, with a firm reliance on the protection of divineProvidence, we mutually pledge to each other our Lives, our Fortunes and our sacred Honor.[The 56 signatures on the Declaration were arranged in six columns:] [Column 1] Georgia:   Button Gwinnett   Lyman Hall   George Walton [Column 2] North Carolina:   William Hooper   Joseph Hewes   John Penn South Carolina:   Edward Rutledge   Thomas Heyward, Jr.  Thomas Lynch, Jr.  Arthur Middleton [Column 3] Massachusetts:   John Hancock Maryland:   Samuel Chase   William Paca   Thomas Stone   Charles Carroll of Carrollton Virginia:   George Wythe   Richard Henry Lee   Thomas Jefferson   Benjamin Harrison   Thomas Nelson, Jr.   Francis Lightfoot Lee   Carter Braxton [Column 4] Pennsylvania:  Robert Morris   Benjamin Rush   Benjamin Franklin   John Morton'},\n",
       " {'page_number': 2,\n",
       "  'page_char_count': 2724,\n",
       "  'page_word_count': 420,\n",
       "  'page_sentence_count_raw': 15,\n",
       "  'page_token_count': 681.0,\n",
       "  'text': 'to render it at once an example and fit instrument for introducing the sameabsolute rule into these Colonies:For taking away our Charters, abolishing our most valuable Laws, and alteringfundamentally the Forms of our Governments:For suspending our own Legislatures, and declaring themselves invested withpower to legislate for us in all cases whatsoever.He has abdicated Government here, by declaring us out of his Protection andwaging War against us.He has plundered our seas, ravaged our Coasts, burnt our towns, and destroyed thelives of our people.He is at this time transporting large Armies of foreign Mercenaries to compleatthe works of death, desolation and tyranny, already begun with circumstances ofCruelty & perfidy scarcely paralleled in the most barbarous ages, and totallyunworthy of the Head of a civilized nation.He has constrained our fellow Citizens taken Captive on the high Seas to bearArms against their Country, to become the executioners of their friends andBrethren, or to fall themselves by their Hands.He has excited domestic insurrections amongst us, and has endeavoured to bringon the inhabitants of our frontiers, the merciless Indian Savages, whose knownrule of warfare, is an undistinguished destruction of all ages, sexes and conditions. In every stage of these Oppressions We have Petitioned for Redress in the most humble terms:Our repeated Petitions have been answered only by repeated injury. A Prince whose character isthus marked by every act which may define a Tyrant, is unfit to be the ruler of a free people. Nor have We been wanting in attentions to our Brittish brethren. We have warned them fromtime to time of attempts by their legislature to extend an unwarrantable jurisdiction over us. Wehave reminded them of the circumstances of our emigration and settlement here. We haveappealed to their native justice and magnanimity, and we have conjured them by the ties of ourcommon kindred to disavow these usurpations, which, would inevitably interrupt ourconnections and correspondence. They too have been deaf to the voice of justice and ofconsanguinity. We must, therefore, acquiesce in the necessity, which denounces our Separation,and hold them, as we hold the rest of mankind, Enemies in War, in Peace Friends. We, therefore, the Representatives of the united States of America, in General Congress,Assembled, appealing to the Supreme Judge of the world for the rectitude of our intentions, do,in the Name, and by Authority of the good People of these Colonies, solemnly publish anddeclare, That these United Colonies are, and of Right ought to be Free and Independent States;that they are Absolved from all Allegiance to the British Crown, and that all political connection'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(pages_and_texts, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51ca7d25-b8e6-4931-9ece-4435d4105bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
      "0            0             2878              448                       14   \n",
      "1            1             1980              300                        9   \n",
      "2            2             2724              420                       15   \n",
      "3            3             1131              212                        6   \n",
      "4            4              623              134                        1   \n",
      "\n",
      "   page_token_count                                               text  \n",
      "0            719.50  Declaration of IndependenceIN CONGRESS, July 4...  \n",
      "1            495.00  He has dissolved Representative Houses repeate...  \n",
      "2            681.00  to render it at once an example and fit instru...  \n",
      "3            282.75  between them and the State of Great Britain, i...  \n",
      "4            155.75  George Clymer   James Smith   George Taylor   ...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a29d070-fd3c-4315-8d53-31bd6196e4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
      "count         5.00             5.00             5.00                     5.00   \n",
      "mean          2.00          1867.20           302.80                     9.00   \n",
      "std           1.58           982.16           133.76                     5.79   \n",
      "min           0.00           623.00           134.00                     1.00   \n",
      "25%           1.00          1131.00           212.00                     6.00   \n",
      "50%           2.00          1980.00           300.00                     9.00   \n",
      "75%           3.00          2724.00           420.00                    14.00   \n",
      "max           4.00          2878.00           448.00                    15.00   \n",
      "\n",
      "       page_token_count  \n",
      "count              5.00  \n",
      "mean             466.80  \n",
      "std              245.54  \n",
      "min              155.75  \n",
      "25%              282.75  \n",
      "50%              495.00  \n",
      "75%              681.00  \n",
      "max              719.50  \n"
     ]
    }
   ],
   "source": [
    "# Get stats\n",
    "print(df.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6294300a-648a-4ced-a8aa-fc2d8b98f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31e0e1f2-9c89-4388-90ec-c928e9f7b4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb2e7125703492c83138a03e2bdca20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "\n",
    "    # Make sure all sentences are strings\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "\n",
    "    # Count the sentences\n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54803838-5d0e-4689-b81a-263676aec433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
      "count         5.00             5.00             5.00                     5.00   \n",
      "mean          2.00          1867.20           302.80                     9.00   \n",
      "std           1.58           982.16           133.76                     5.79   \n",
      "min           0.00           623.00           134.00                     1.00   \n",
      "25%           1.00          1131.00           212.00                     6.00   \n",
      "50%           2.00          1980.00           300.00                     9.00   \n",
      "75%           3.00          2724.00           420.00                    14.00   \n",
      "max           4.00          2878.00           448.00                    15.00   \n",
      "\n",
      "       page_token_count  page_sentence_count_spacy  \n",
      "count              5.00                       5.00  \n",
      "mean             466.80                       9.80  \n",
      "std              245.54                       5.07  \n",
      "min              155.75                       3.00  \n",
      "25%              282.75                       6.00  \n",
      "50%              495.00                      12.00  \n",
      "75%              681.00                      13.00  \n",
      "max              719.50                      15.00  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "print(df.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef4d8d0c-af14-408a-9277-3958a48a9699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08840957b6bf4ecf94510ec5877efbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define split size to turn groups of sentences into chunks\n",
    "num_sentence_chunk_size = 10\n",
    "# Create a function that recursively splits a list into desired sizes\n",
    "def split_list(input_list, slice_size):\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "# Loop through pages and texts and split sentences into chunks\n",
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentences\"] = item[\"text\"].split(\".\")\n",
    "    item[\"sentences\"] = [sentence.strip() + '.' for sentence in item[\"sentences\"] if sentence.strip()]\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"], slice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c694e30-7871-40c4-9cd1-96cc79f0ac59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
      "count         5.00             5.00             5.00                     5.00   \n",
      "mean          2.00          1867.20           302.80                     9.00   \n",
      "std           1.58           982.16           133.76                     5.79   \n",
      "min           0.00           623.00           134.00                     1.00   \n",
      "25%           1.00          1131.00           212.00                     6.00   \n",
      "50%           2.00          1980.00           300.00                     9.00   \n",
      "75%           3.00          2724.00           420.00                    14.00   \n",
      "max           4.00          2878.00           448.00                    15.00   \n",
      "\n",
      "       page_token_count  page_sentence_count_spacy  num_chunks  \n",
      "count              5.00                       5.00        5.00  \n",
      "mean             466.80                       9.80        1.40  \n",
      "std              245.54                       5.07        0.55  \n",
      "min              155.75                       3.00        1.00  \n",
      "25%              282.75                       6.00        1.00  \n",
      "50%              495.00                      12.00        1.00  \n",
      "75%              681.00                      13.00        2.00  \n",
      "max              719.50                      15.00        2.00  \n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe to get stats\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "print(df.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be3fbe7e-e804-4ece-9cb2-701c01c2c6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72a8022d643492684be144351ad425b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "#splitting each chunk into its own size\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_and_texts):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk)\n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4\n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "# How many chunks do we have?\n",
    "print(len(pages_and_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28647004-5921-4969-8ced-69b53c8b772e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
      "count         7.00              7.00              7.00               7.00\n",
      "mean          1.71           1328.14            210.43             332.04\n",
      "std           1.50            654.54            100.47             163.63\n",
      "min           0.00            596.00             98.00             149.00\n",
      "25%           0.50            820.50            129.50             205.12\n",
      "50%           2.00           1105.00            185.00             276.25\n",
      "75%           2.50           1864.50            290.00             466.12\n",
      "max           4.00           2226.00            351.00             556.50\n"
     ]
    }
   ],
   "source": [
    "# Get stats about our chunks\n",
    "df = pd.DataFrame(pages_and_chunks)\n",
    "print(df.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3f37fb4-15c3-47c7-b73e-fc3048d65809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019be6cd856b4715b13a5b3e608bda4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Detect grammatical errors\n",
    "errors = []\n",
    "for item in tqdm(pages_and_texts):\n",
    "    for sentence in item[\"sentences\"]:\n",
    "        original_sentence, corrected_sentence = grammer_checker.correct_grammar(sentence)\n",
    "        highlighted_sentence = grammer_checker.highlight_errors(original_sentence, corrected_sentence)\n",
    "        if original_sentence != corrected_sentence:\n",
    "            errors.append({\n",
    "                \"page_number\": item[\"page_number\"],\n",
    "                \"original_sentence\": original_sentence.strip(),\n",
    "                \"corrected_sentence\": corrected_sentence.strip(),\n",
    "                \"highlighted_sentence\": highlighted_sentence.strip()\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12f61076-3468-444b-9dd6-cd9dccd9c6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 0: Declaration of **IndependenceIN** **CONGRESS,** **July** **4,** **1776.**\n",
      "Page 0: The un**a**nimous Declaration ********of******** ************the************ thirteen **un**it**ed** States of America, When in the **Course** of human events, it **becomes** **necessary** **for** **one** **people** **********to********** **dissolve** **thepolitical** **b******and******s** ****which**** **have** **connected** ****them**** **with** **another,** and to **assume** **among** the **powers** of **theearth,** the **separate** and **equal** **station** to which the **Laws** of **Nature** and of **Nature's** **God** **entitlethem,** a **decent** **respect** to the **opinions** of **mankind** **requires** **that** **they** **should** **declare** the **causeswhich** **impel** them to the **separation.**\n",
      "Page 0: We hold ****the**se** truths to be self-evident, ****that**** all men ****are**** created **equal,** that **they** are **endowed** **bytheir** **Creator** **with** **certain** **unalienable** **Rights,** that **among** these are **Life,** **Liberty** **and** the **pursuitof** **Happiness.**\n",
      "Page 0: — ****\u0014That**** ********to******** secure ********the********se rights, Governments are inst**it**uted am**on**g Men, **deriving**their**** **just** ****powers**** **from** the **consent** ********of******** the **governed,—**  \u0014That **whenever** **any** **F**or**m** of **Governmentbecomes** **destructive** of **these** **ends,** it **is** the **Right** of the **People** to **alter** or to **abolish** **it,** ******and****** **toinstitute** **new** **Government,** **laying** ****its**** **foundation** on **such** **principles** and **organizing** its powers **insuch** **form,** **as** to **them** **shall** **seem** **most** **likely** to **effect** their **Safety** and **Happiness.**\n",
      "Page 0: **Prudence,indeed,** **will** **dictate** ****that**** **Governments** **long** **established** **should** **not** **be** **changed** **for** **light** ****and**transient** **causes;** and **accordingly** **all** **experience** **hath** **shewn,** that **mankind** ****are**** **more** **disposed** ******to****suffer,** **while** **evils** are **sufferable,** **than** to **right** ****the**mselves** **by** **abolishing** the **forms** to **which** **theyare** **accustomed.**\n",
      "Page 0: But when **a** long train of abuses **and** usurpations, pursuing **invariably** **the** **sameObject** **evinces** a **design** ****to**** **reduce** **them** **under** **absolute** **Despot****is****m,** ****it**** is ******their****** **right,** it is their **duty,to** **throw** **off** **such** **Government,** and to **provide** **new** **Guards** **for** their **future** **security.**\n",
      "Page 0: — **\u0014Such** **hasbeen** ****the**** **patient** **sufferance** ****of**** **these** **Colonies;** **and** **such** **is** **now** the **necessity** **which** **constrainsthem** **to** **alter** **their** **former** **Systems** of **Government.**\n",
      "Page 0: The h**is**tory ****of**** the present K**in**g of **Gre**a**tBritain** is a **history** of **repeated** **injuries** ****an**d** **usurpations,** **all** **having** in **direct** **object** **theestablishment** of an **absolute** **Tyranny** **over** **these** **States.**\n",
      "Page 0: He has refused his Assent to Laws, the most wholesome and necessary for **thepublic** **good.**\n",
      "Page 0: He **has** forbidden **his** Governors ****to**** pass Laws of immediate and **press**in**gimportance,** **unless** **suspended** in **t**he**ir** **operation** **till** his **Assent** **should** **be** **obtained;and** **when** **so** **suspended,** he has **utterly** **neglected** to **attend** to **them.**\n",
      "Page 0: He h**a**s refused ****to**** pass o**the**r Laws for the accommodation **of** large districts **of**people**,** **unless** **those** people **would** **rel**in**quish** the ****right**** of **Representation** in **theLegislature,** a right **inestimable** to **them** **and** **formidable** to **tyrants** **only.**\n",
      "Page 0: He has called toge****the****r legislative bodies at places unusual, uncom**for**table, and **distantfrom** the **depository** ****of**** **their** **public** **Records,** for the **sole** **purpose** of **fatiguing** **them** **intocompliance** **with** **his** **measures.**\n",
      "Page 1: He has dissolved Representative Houses repeatedly, for opposing with manlyfirmness his **invasi**on**s** on ****the**** **rights** **of** the **people.**\n",
      "Page 1: He has refused **for** a long time, after such dissolutions, **to** cause o**********the**********rs to **beelected;** **whereby** the **Legisl**at**ive** **powers,** ****in**capable** ****of**** **Annihilation,** **have** **returnedto** the **People** at **large** for **their** **exercise;** the **State** **remaining** in the **mean** **timeexposed** to **all** the **dangers** of **invasion** **from** **without,** **and** **convulsions** **within.**\n",
      "Page 1: He has endeavoured **to** prevent ****the**** population ******of****** these States; **for** that **purposeobstructing** the **Laws** for **Naturalization** of **Foreigners;** **refusing** to **pass** **others** **toencourage** **their** **migrations** **hither,** **and** **raising** the **conditions** of **newAppropriations** of **Lands.**\n",
      "Page 1: He has obstructed the Administration of **Justice,** by refusing his Assent to **Lawsfor** **establishing** **Judiciary** **powers.**\n",
      "Page 1: He has made **Judges** dependent on his Will alone, for **the** tenure **of** **their** **offices,**and**** the **amount** and **payment** of their **salaries.**\n",
      "Page 1: He has erected a multitude **of** New Offices, **and** sent **hither** **swarms** of **Officers** **toharrass** **our** **people,** and **eat** **out** **their** **substance.**\n",
      "Page 1: He has kept among us, in times of peace, Standing Armies without the **Consent** **ofour** **legislatures.**\n",
      "Page 1: He h****a****s comb****in****ed **with** o********the********rs ****to**** subject ******us****** to a jurisdicti****on**** ****for****eign to ********our******constitution,** ****an**d** **unacknowledged** ******by****** our **laws;** **giving** **his** **Assent** to **their** **Acts** ************of************pretended**** **Legislation:**For**** **Quartering** **large** **bodies** of **armed** **troops** **among** **us:For** **protecting** **them,** by a **mock** ****Trial**,** **from** **punishment** for **any** **Murders** **whichthey** **should** **commit** on the **Inhabitants** of **these** **States:For** **cutting** **off** our **Trade** with **all** **parts** of the **world:For** **imposing** **Taxes** on us **without** our **Consent:** For **depriving** us in **many** **cases,of** the ****be**nef**its**** of Trial by **Jury:For** **transporting** us **beyond** **Seas** to be **tried** for pretended **offencesFor** **abolishing** the **free** **System** of **English** **Laws** in a **neighbouring** **Province,establishing** **therein** an **Arbitrary** **government,** **and** **enlarging** its **Boundaries** **so** **as.**\n",
      "Page 2: ****to**** render it at once an example ****and**** fit **in**strument **for** introducing **the** sameabsolute rule **into** **these** **Colonies:For** **taking** **away** ********our******** **Charters,** **abolishing** our **most** **valuable** **Laws,** and **alteringfundament**all**y** the **Forms** **of** our **Governments:For** **s**us**pending** our **own** **Legislatures,** and **declaring** **themselves** **invested** **withpower** to **legislate** for us in all **cases** **whatsoever.**\n",
      "Page 2: He has abdicated Government here, by declaring us out of his Protection andwaging **War** **against** **us.**\n",
      "Page 2: He has plundered **our** seas, ravaged our **Coasts,** **burnt** our **towns,** **and** **destroyed** **thelives** **of** our **people.**\n",
      "Page 2: He is **a**t this time transport**in**g large Armies ******of****** foreign Mercenaries to **compleat****the****** **works** of **death,** **desolation** ****and**** **tyranny,** **already** **begun** **with** **circumstances** **ofCruelty** **&** **perfidy** **scarcely** **paralleled** in the **most** **barbarous** **ages,** and **totallyunworthy** of the **Head** of a **civilized** **nation.**\n",
      "Page 2: He has constrained our fellow **Citizens** taken **Captive** on **the** high **Seas** ****to**** **bearArms** **against** ******their****** **Country,** to **become** the **executioners** **of** their **friends** **andBrethren,** **or** to **fall** **themselves** **by** their **Hands.**\n",
      "Page 2: He has excited domestic insurrections amongst us, **an**d has endeav**our**ed **to** **bringon** ****the**** **inhabitants** ******of****** our **frontiers,** the **merciless** **Indian** **Sav**ages,**** **whose** **knownrule** of **warfare,** **is** an **undistinguished** **destruction** of **all** ages, **sexes** **and** **conditions.**\n",
      "Page 2: In every stage of these **Oppressions** **We** **have** **Petitioned** for Redress in the **most** **humble** **terms:Our** ****repeated**** **Petitions** have **been** **answered** **only** **by** repeated **injury.**\n",
      "Page 2: A Prince whose ch**a**racter **isthus** marked by every act which may define a Tyrant, is **unfit** **to** **be** **the** **ruler** **of** a **free** **people.**\n",
      "Page 2: Nor have **We** been want**in**g in **attentions** **to** **our** **Brittish** **brethren.**\n",
      "Page 2: We have warned them **from**time**** ****to**** time **of** **attempts** **by** **their** **legislature** to **extend** **an** **unwarrantable** **jurisdiction** **over** **us.**\n",
      "Page 2: **Wehave** **reminded** ****the**m** ****of**** the **circumstances** of **our** **emigration** **and** **settlement** **here.**\n",
      "Page 2: We haveappealed **to** **the**ir native justice **and** magnanimity, and we have **conjured** **them** **by** the **ties** **of** **ourcommon** **kindred** to **disavow** **these** **usurpations,** **which,** **would** **inevitably** **interrupt** **ourconnections** and **correspondence.**\n",
      "Page 2: We must, **the**refore, acquiesce ****in**** the necessity, which denounces **our** **Separation,and** ****hold**** **them,** **as** **we** hold the **rest** **of** **mankind,** **Enemies** in **War,** in **Peace** **Friends.**\n",
      "Page 2: We, ************the************re**for**e, the Representatives **********of********** the **united** States of America, in General **Congress,Assembled,** **appealing** ******to****** the **Supreme** **Judge** of the **world** for the **rectitude** of **our** **intentions,** **do,in** the **Name,** ********and******** **by** **Authority** of the **good** **People** of ****these**** ****Colonies**,** **solemnly** **publish** **anddecl****are**,**** **That** these **United** Colonies are, and of **Right** **ought** to **be** **Free** and **Independent** **States;**that**** **they** are **Absolved** **from** ****all**** **Allegiance** to the **British** **Crown,** and that all **political** **connection.**\n",
      "Page 3: ****be**tween** ****the**m** **********and********** the **State** ****of**** **Great** **Britain,** **is** and **ought** ******to****** be **tot**all**y** **dissolved;** and **that** **as** **Freeand** ****Independent**** ****States**,** **they** **have** **full** **Power** to **levy** **War,** **conclude** **Peace,** **contract** **Alliances,establish** **Commerce,** and to **do** all **other** **Acts** and **Things** **which** Independent States **may** of **rightdo.**\n",
      "Page 3: And for the support of this Declaration, with a firm reliance on the protection of **divineProvidence,** **we** **mutually** **pledge** **to** **each** **other** ******our****** **Lives,** our **Fortunes** **and** our **sacred** **Honor.**\n",
      "Page 3: **[The** 56 signatures on the Declaration were arranged in six columns:] **[Column** **1]** **Georgia:**   **Button** **Gwinnett**   **Lyman** **Hall**   **George** **Walton** [Column **2]** **North** ****Carolina:****   **William** **Hooper**   **Joseph** **Hewes**   **John** **Penn** **South** Carolina:   **Edward** **Rutledge**   **Thomas** **Heyward,** **Jr.**\n",
      "Page 3: Arthur Middleton [Column 3] Massachusetts:   John Hancock Maryland:   Samuel Chase   **William** **Paca**   ******Thomas****** **Stone**   **Charles** **Carroll** **of** **Carrollton** **Virginia:**   **George** **Wythe**   **Richard** **Henry** **Lee**   Thomas **Jefferson**   **Benjamin** **Harrison**   Thomas **Nelson,** **Jr.**\n",
      "Page 3: Francis Lightfoot Lee   Carter Braxton [Column 4] Pennsylvania:  Robert Morris   **Benjamin** Rush   Benjamin **Franklin**   **John** **Morton.**\n",
      "Page 4: George Clymer   James Smith   George Taylor   James Wilson   George Ross Delaware:   Caesar Rodney   George Read   **Thomas** **McKean** ****[Column**** **5]** ********New******** **York:**   ********William******** **Floyd**   **Philip** **Livingston**   ****Francis**** ****Lewis****   Lewis **Morris** New **Jersey:**   **Richard** **Stockton**   ******John****** **Witherspoon**   Francis ****Hopkins**on**   John **Hart**   **Abraham** **Clark** [Column **6]** New ****Hampshire:****   **Josiah** **Bartlett**   William **Whipple** **Massachusetts:**   ****Samuel**** ****Adams****   John Adams   **Robert** **Treat** **Paine**   **Elbridge** **Gerry** **Rhode** **Island:**   **Stephen** Hopkins   William **Ellery** **Connecticut:**   **Roger** **Sherman**   Samuel **Huntington**   William **Williams**   **Oliver** **Wolcott** New Hampshire: **Matthew** **Thornton.**\n"
     ]
    }
   ],
   "source": [
    "# Display highlighted sentences with errors\n",
    "for error in errors:\n",
    "    print(f\"Page {error['page_number']}: {error['highlighted_sentence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c4aae3-dc53-435d-b05c-f46a8844c35f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
